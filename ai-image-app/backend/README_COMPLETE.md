# ğŸš€ Complete AI Image Generator System

**Your Mac M3-powered custom AI image generation system with LoRA training, web interface, and production deployment.**

## ğŸ‰ What You Have

âœ… **Custom LoRA Model** - Trained on LAION-2B dataset  
âœ… **Mac M3 GPU Acceleration** - MPS backend for fast training  
âœ… **Web Interface** - Next.js frontend + Flask backend  
âœ… **Production Ready** - Complete API with multiple endpoints  
âœ… **Training Pipeline** - MPS-compatible LoRA training  

## ğŸ“ System Structure

```
ai-image-app/
â”œâ”€â”€ backend/                    # Flask API server
â”‚   â”œâ”€â”€ app.py                 # Main Flask application
â”‚   â”œâ”€â”€ generate_fast.py       # Fast image generation
â”‚   â”œâ”€â”€ generate_working.py    # Working generation script
â”‚   â”œâ”€â”€ train_custom_model_mps.py  # MPS LoRA training
â”‚   â”œâ”€â”€ train_lora_fixed.py    # Fixed LoRA training
â”‚   â”œâ”€â”€ test_custom_model.py   # Model testing
â”‚   â”œâ”€â”€ one_click_launcher.sh  # Complete system launcher
â”‚   â”œâ”€â”€ launch_training.sh     # Training launcher
â”‚   â”œâ”€â”€ training_config.json   # Training configuration
â”‚   â”œâ”€â”€ lora_weights/          # Trained LoRA models
â”‚   â”œâ”€â”€ generated_images/      # Generated images
â”‚   â””â”€â”€ training_logs/         # Training history
â””â”€â”€ frontend/                  # Next.js web interface
    â”œâ”€â”€ app/                   # React components
    â”œâ”€â”€ package.json           # Dependencies
    â””â”€â”€ next.config.ts         # Next.js config
```

## ğŸš€ Quick Start

### 1. One-Click Launch (Recommended)

```bash
cd ai-image-app/backend
chmod +x one_click_launcher.sh
./one_click_launcher.sh
```

This will:
- âœ… Check system requirements
- âœ… Activate virtual environment
- âœ… Start backend server (port 5001)
- âœ… Start frontend server (port 3000)
- âœ… Test image generation
- âœ… Show system status

### 2. Manual Launch

#### Start Backend Only
```bash
cd ai-image-app/backend
source venv/bin/activate
python app.py
```

#### Start Frontend Only
```bash
cd ai-image-app/frontend
npm run dev
```

#### Generate Images
```bash
cd ai-image-app/backend
source venv/bin/activate
python generate_working.py
```

## ğŸ§  Training Your Custom Model

### Option 1: Fixed LoRA Training (Recommended)

```bash
cd ai-image-app/backend
source venv/bin/activate
python train_lora_fixed.py
```

**Features:**
- âœ… Correct task type for SD compatibility
- âœ… MPS GPU acceleration
- âœ… LAION-2B dataset streaming
- âœ… Automatic checkpointing

### Option 2: MPS LoRA Training

```bash
cd ai-image-app/backend
./launch_training.sh
```

**Features:**
- âœ… Full MPS optimization
- âœ… Environment variable setup
- âœ… Comprehensive error checking

### Training Configuration

Edit `training_config.json` to customize:

```json
{
  "training": {
    "base_model": "runwayml/stable-diffusion-v1-5",
    "resolution": 512,
    "batch_size": 1,
    "max_train_steps": 5000,
    "learning_rate": 1e-4
  },
  "lora": {
    "r": 16,
    "lora_alpha": 32,
    "target_modules": ["to_q", "to_k", "to_v", "to_out.0", "ff.net.0.proj", "ff.net.2"],
    "task_type": "CAUSAL_LM"
  },
  "datasets": [
    {
      "name": "laion/laion2B-en",
      "streaming": true,
      "filter": "caption_length_10_200"
    }
  ]
}
```

## ğŸ¨ Image Generation

### Web Interface
Visit: **http://localhost:3000**

### API Endpoints

#### Generate with Base Model
```bash
curl -X POST http://localhost:5001/generate_fast \
  -H "Content-Type: application/json" \
  -d '{"prompt": "A beautiful sunset over mountains"}'
```

#### Generate with Custom LoRA
```bash
curl -X POST http://localhost:5001/generate_custom \
  -H "Content-Type: application/json" \
  -d '{"prompt": "A beautiful sunset over mountains"}'
```

#### Health Check
```bash
curl http://localhost:5001/health
```

### Command Line Generation

#### Working Generation (Base Model)
```bash
python generate_working.py
```

#### Custom LoRA Generation
```bash
python generate_with_custom_lora.py
```

#### Test Custom Model
```bash
python test_custom_model.py
```

## ğŸ“Š System Monitoring

### Check System Status
```bash
./one_click_launcher.sh
# Choose option 5: Show System Status
```

### Monitor Training
```bash
# Watch training logs
tail -f training_logs/training_info_*.json

# Check GPU usage (if available)
sudo powermetrics --samplers gpu_power -n 1
```

### Check Generated Images
```bash
ls -la generated_images/
ls -la lora_weights/
```

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. MPS Not Available
```bash
python3 -c "import torch; print(torch.backends.mps.is_available())"
# Should return: True
```

#### 2. Hugging Face Authentication
```bash
huggingface-cli login
# Enter your token from: https://huggingface.co/settings/tokens
```

#### 3. Port Already in Use
```bash
# Stop existing services
pkill -f "python3 app.py"
pkill -f "npm run dev"

# Or change ports in app.py and next.config.ts
```

#### 4. Out of Memory
```bash
# Reduce batch size in training_config.json
"batch_size": 1,
"gradient_accumulation_steps": 8
```

### Performance Optimization

#### For Mac M3
- âœ… Keep batch_size=1 for stability
- âœ… Use 512x512 resolution for training
- âœ… Close other apps during training
- âœ… Keep Mac cool for best performance

#### For Better Results
- âœ… Train for 5000-10000 steps on LAION-2B
- âœ… Use learning rate 1e-4 to 5e-5
- âœ… LoRA rank 16-32 for quality
- âœ… Mix LAION-2B with custom datasets

## ğŸš€ Deployment Options

### 1. Local Production
```bash
# Backend with production settings
export FLASK_ENV=production
python app.py

# Frontend build
cd frontend
npm run build
npm start
```

### 2. Cloud Deployment

#### Backend (Flask)
- **Render.com**: Easy deployment with GPU support
- **Railway**: Simple container deployment
- **Heroku**: Traditional deployment (no GPU)

#### Frontend (Next.js)
- **Vercel**: Optimized for Next.js
- **Netlify**: Static site hosting
- **Cloudflare Pages**: Fast global CDN

#### GPU Backend
- **RunPod**: Pay-per-use GPU instances
- **Lambda Labs**: Affordable GPU cloud
- **Google Colab Pro**: Jupyter-based training

### 3. Hugging Face Spaces
```bash
# Create a Hugging Face Space for your model
# Upload your LoRA weights and create a demo
```

## ğŸ“ˆ Advanced Features

### Custom Datasets

Create your dataset structure:
```
your_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ captions.txt
# Format: image1.jpg|A fantasy ruin glowing in moonlight
```

Update `training_config.json`:
```json
{
  "custom_datasets": [
    {
      "type": "imagefolder",
      "data_dir": "path/to/your/dataset",
      "description": "Your custom style"
    }
  ]
}
```

### SDXL Training

For SDXL models, update configuration:
```json
{
  "training": {
    "base_model": "stabilityai/stable-diffusion-xl-base-1.0",
    "resolution": 1024,
    "max_train_steps": 3000
  },
  "lora": {
    "target_modules": [
      "down_blocks.*.attentions.*.transformer_blocks.*.attn1.*",
      "mid_block.attentions.*.transformer_blocks.*.attn1.*",
      "up_blocks.*.attentions.*.transformer_blocks.*.attn1.*"
    ]
  }
}
```

### HD Generation

Use the HD generation script for high-resolution images:
```bash
python generate_hd.py
```

## ğŸ¯ Success Indicators

### Training Success
- âœ… `"device": "mps"` in training logs
- âœ… `"lora_success": true`
- âœ… Loss decreasing over time
- âœ… LoRA weights saved in `lora_weights/`

### Generation Success
- âœ… Images generated in `generated_images/`
- âœ… Web interface accessible at `http://localhost:3000`
- âœ… API endpoints responding
- âœ… No errors in console

### System Health
- âœ… Backend: `http://localhost:5001/health` returns 200
- âœ… Frontend: `http://localhost:3000` loads
- âœ… GPU: MPS available and working
- âœ… Memory: Sufficient RAM for generation

## ğŸ“š Documentation

- **Training Guide**: `MPS_TRAINING_GUIDE.md`
- **Quick Start**: `QUICK_START.md`
- **API Docs**: Check Flask routes in `app.py`
- **Frontend Docs**: Next.js documentation

## ğŸ†˜ Support

### Quick Commands Reference
```bash
# Start everything
./one_click_launcher.sh

# Generate images
python generate_working.py

# Train LoRA
python train_lora_fixed.py

# Test system
python test_custom_model.py

# Stop services
pkill -f "python3 app.py" && pkill -f "npm run dev"

# Check status
curl http://localhost:5001/health
```

### Getting Help
1. Check logs: `tail -f training_logs/*.json`
2. Verify MPS: `python -c "import torch; print(torch.backends.mps.is_available())"`
3. Test generation: `python generate_working.py`
4. Check memory: Activity Monitor â†’ Memory tab

## ğŸ‰ Congratulations!

You now have a **complete, production-ready AI image generation system** running on your Mac M3 with:

- âœ… **Custom LoRA training** on LAION-2B
- âœ… **GPU acceleration** via MPS
- âœ… **Web interface** for easy use
- âœ… **API endpoints** for integration
- âœ… **Production deployment** options

**Your system is ready to create amazing AI-generated images!** ğŸš€ 